require 'nn'
require 'nngraph'

--require 'Rectifier'

--local CNN = require 'CNN'
local LSTM = require 'LSTM'
local model_utils = require 'model_utils'

local TrackNet = torch.class('detection.TrackNet')
local utils = detection.GeneralUtils()
function TrackNet:__init(model_path,weight_file_path,model_opt)
        -- rnn opts
        self.rnn_size = model_opt.rnn_size
        self.minibatch_size = model_opt.minibatch_size
        self.gpu = model_opt.gpu
        self.nactions = model_opt.nactions
        self.hist_len = model_opt.hist_len

	self.model_path = model_path
	self.weight_file_path = weight_file_path
	self.model_opt = model_opt
	
    	if model_path == nil then
		error 'The first argument can not be nil!'
	end

	self.model = {}
	-- build CNN model with ROIPooling, LSTM, output layer
	self.model.cnn,self.model.cnn_name = dofile(model_path)(model_opt)
        self.model.lstm = LSTM.lstm(model_opt)
        self.model.dqn = nn.Linear(self.rnn_size,1)

        -- set to gpu
        if self.gpu >= 0 then
            self.model.cnn:cuda()
            self.model.lstm:cuda()
            self.model.dqn:cuda()
        end

        -- set parallel
	if config.nGPU > 1 and not model_opt.test then
		self:_makeParallel()
	end
        
        
        -- index parameters and gradParameters
        self.parameters, self.gradParameters = model_utils.combine_all_parameters(self.model.cnn, self.model.lstm, self.model.dqn)
        self.gradParameters:zero()
        
        -- clone for hist_len times
        self.clones = {}
        for name,proto in pairs(self.model) do
	    print('cloning '..name)
	    self.clones[name] = model_utils.clone_many_times(proto, args.hist_len, not proto.parameters)
	end

	-- LSTM initial state (zero initially, but final state gets sent to initial state when we do BPTT)
	self.initstate_c = torch.zeros(self.minibatch_size, self.rnn_size)
	self.initstate_h = self.initstate_c:clone()
	if self.gpu >=0 then
		self.initstate_c = self.initstate_c:cuda()
		self.initstate_h = self.initstate_h:cuda()
	end

	-- LSTM final state's backward message (dloss/dfinalstate) is 0, since it doesn't influence predictions
	self.dfinalstate_c = self.initstate_c:clone()

	-- LSTM initial state for prediction, note that we're using minibatches OF SIZE ONE here
	self.prev_c = torch.zeros(1, self.rnn_size)
	self.prev_h = self.prev_c:clone()
	if self.gpu >=0 then
		self.prev_c = self.prev_c:cuda()
		self.prev_h = self.prev_h:cuda()
	end

	--self.parameters, self.gradParameters = self.model:getParameters()
        -- load weight_file for cnn
	if weight_file_path~=nil then
		self:load_weight()
	end
end


function TrackNet:clone()
    local mem = torch.MemoryFile("w"):binary()
    mem:writeObject(self)
    local reader = torch.MemoryFile(mem:storage(), "r"):binary()
    local clone = reader:readObject()
    reader:close()
    mem:close()
    return clone
end


function TrackNet:_makeParallel()
	local gpus = torch.range(1, config.nGPU):totable()
	local fastest, benchmark = cudnn.fastest, cudnn.benchmark
	local parallel_model = nn.DataParallelTable(1,true,true):cuda():add(self.model,gpus)
	:threads(function()
            local cudnn = require 'cudnn'
            local inn = require 'inn'
            local detection = require 'detection'
            cudnn.fastest, cudnn.benchmark = fastest, benchmark
         end)
      parallel_model.gradInput = nil

     self.model = parallel_model:cuda()
end

--function Net:_prepare_regressor(means,stds)
--	stds[{{1,4}}] = 1.0
--	self.regressor.weight = self.regressor.weight:cdiv(stds:expand(self.regressor.weight:size()))
--	self.regressor.bias = self.regressor.bias - means:view(-1)
--	self.regressor.bias = self.regressor.bias:cdiv(stds:view(-1))
--end

--function Net:initialize_for_training()
	-- initialize classifier and regressor with appropriate random numbers 
--	self.classifier.weight:normal(0,0.01)
--	self.classifier.bias:fill(0)
--	self.regressor.weight:normal(0,0.001)
--	self.regressor.bias:fill(0)
--end

function TrackNet:load_weight(weight_file_path)

	if weight_file_path~=nil then
		self.weight_file_path = weight_file_path
	end
	local loaded_model = torch.load(self.weight_file_path)


	-- See if the loaded model supports our naming method for loading the weights
	local has_name = false
	local loaded_modules = loaded_model:listModules()
	for i=1,#loaded_modules do
		if loaded_modules[i].name then
			has_name = true
			break
		end
	end
	if has_name then
		-- Load the weights based on names
		local model_modules = self.model:listModules()
		for i=1,#loaded_modules do
			local copy_name = loaded_modules[i].name
			if copy_name then
				for j=1,#model_modules do
					local my_name = model_modules[j].name
					if my_name and my_name == copy_name then
						print('Copying weights from ' .. my_name .. ' layer!')
						model_modules[j].weight:copy(loaded_modules[i].weight)
						model_modules[j].bias:copy(loaded_modules[i].bias)
					end
				end
			end
		end
	else
		if self.model_opt.fine_tunning then
			-- romove the last layer then
			loaded_model:remove(#loaded_model.modules)
		end
		-- Loading parameters
		params = loaded_model:getParameters()
		-- Copying parameters

	 	self.parameters[{{1,params:size(1)}}]:copy(params)
	 end
 end

function TrackNet:getParameters()
	return self.parameters, self.gradParameters
end

function TrackNet:training()
	self.model.cnn:training()
	self.model.lstm:training()
	self.model.dqn:training()
end

function TrackNet:evaluate()
	self.model.cnn:evaluate()
	self.model.lstm:evaluate()
	self.model.dqn:evaluate()
end

function TrackNet:save(save_path,means,stds)
	-- First sanitize the net
	self:_sanitize()
	local isParallel = (torch.type(self.model) == 'nn.DataParallelTable')
	if isParallel then
		self.model = self.model:get(1)
	end
	collectgarbage()
	-- Save the snapshot
	torch.save(save_path,self.model)
	 if isParallel then
	 	self:_makeParallel()
	 end
end

function TrackNet:load_from_caffe(proto_path,caffemodel_path,save_path,model_name)
	caffeModelLoader = detection.CaffeModelConverter(self.model,proto_path,caffemodel_path,model_name,save_path)
	caffeModelLoader:convert()
end

function TrackNet:get_model()
	return self.model
end


function TrackNet:forward(inputs)
  	self.inputs,inputs = utils:recursiveResizeAsCopyTyped(self.inputs,inputs,'torch.CudaTensor')
         ------------------- forward pass -------------------
        self.lstm_c = {[0]=self.initstate_c} -- internal cell states of LSTM
        self.lstm_h = {[0]=self.initstate_h} -- output values of LSTM
    
        self.observation = {}         -- input observation
        self.predictions = {}         -- dqn outputs

        --local input = {}
        --input[1] = self.inputs[1]:reshape(self.minibatch_size, self.hist_len, self.depth, self.height, self.width) -- images
        --input[2] = self.inputs[2]:reshape(self.minibatch_size, self.hist_len, 5)   -- rois

        for t=1,self.hist_len do
            self.observation[t] = self.clones.cnn[t]:forward(self.inputs[t])
            self.lstm_c[t], self.lstm_h[t] = unpack(self.clones.lstm[t]:forward{self.observation[t], self.lstm_c[t-1], self.lstm_h[t-1]})
            self.predictions[t] = self.clones.dqn[t]:forward(self.lstm_h[t])
        end
        
        -- prediction  hist_len x num_rois x 1, num_rois is 50 with the defaut setting
  	--local out = self.model:forward(self.inputs)
  	--return out[1],out[2]
end


function TrackNet:backward(inputs, targets)
    self.inputs,inputs = utils:recursiveResizeAsCopyTyped(self.inputs,inputs,'torch.CudaTensor')

    local input = s:reshape(self.minibatch_size, self.hist_len, self.height, self.width)

    -- zero gradients of parameters
    self.dw:zero()

    ------------------ backward pass -------------------
    -- complete reverse order of the above
    local dobservation = {}                           		-- d loss / d input observation
    local dlstm_c = {[self.hist_len]=self.dfinalstate_c}   	-- internal cell states of LSTM
    local dlstm_h = {}                                		-- output values of LSTM
    for t=self.hist_len,1,-1 do
        -- backprop through loss/target, and DQN/linear
        -- Two cases for dloss/dh_t: 
        --   1. h_T is only used once, sent to the DQN (but not to the next LSTM timestep).
        --   2. h_t is used twice, for the DQN and for the next step. To obey the
        --      multivariate chain rule, we add them.
        if t == self.hist_len then
            assert(dlstm_h[t] == nil)
            dlstm_h[t] = self.clones.dqn[t]:backward(self.lstm_h[t], targets[t])
        else
            dlstm_h[t]:add(self.clones.dqn[t]:backward(self.lstm_h[t], targets[t]))
        end

        -- backprop through LSTM timestep
        dobservation[t], dlstm_c[t-1], dlstm_h[t-1] = unpack(self.clones.lstm[t]:backward(
            {self.observation[t], self.lstm_c[t-1], self.lstm_h[t-1]},
            {dlstm_c[t], dlstm_h[t]}
        ))

        -- backprop through CNN
        self.clones.cnn[t]:backward(input[{{},{t},{},{}}], dobservation[t])
    end

    ------------------------ misc ----------------------
    -- transfer final state to initial state (BPTT)
    --self.initstate_c:copy(self.lstm_c[#self.lstm_c])
    --self.initstate_h:copy(self.lstm_h[#self.lstm_h])

    -- clip gradient element-wise
    self.dw:clamp(-5, 5)
end


-- borrowed from https://github.com/soumith/imagenet-multiGPU.torch/blob/master/train.lua
function TrackNet:_sanitize()
  net = self.model
  local list = net:listModules()
  for _,val in ipairs(list) do
    for name,field in pairs(val) do
      if torch.type(field) == 'cdata' then val[name] = nil end
      if name == 'homeGradBuffers' then val[name] = nil end
      if name == 'input_gpu' then val['input_gpu'] = {} end
      if name == 'gradOutput_gpu' then val['gradOutput_gpu'] = {} end
      if name == 'gradInput_gpu' then val['gradInput_gpu'] = {} end
      if (name == 'output' or name == 'gradInput') then
      	if type(field) ~= 'table' then
        	val[name] = field.new()
        end
      end
    end
  end
end



